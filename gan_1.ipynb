{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“07_PyTorch”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryZhou1002/12306/blob/master/gan_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bOChJSNXtC9g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "0-dXQiLlTIgz",
        "colab_type": "code",
        "outputId": "692bd531-83c2-4e0a-d2e8-b3a0cb3c64bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "# Load PyTorch library\n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Collecting pillow==4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.7MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 5.4.1\n",
            "    Uninstalling Pillow-5.4.1:\n",
            "      Successfully uninstalled Pillow-5.4.1\n",
            "Successfully installed pillow-4.1.1\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rX7Vs1JxL9wX",
        "colab_type": "code",
        "outputId": "a08043cf-9db7-4f25-8810-4d065e42996e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2285
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Jan 19 08:06:53 2019\n",
        "\n",
        "@author: zhouhang\n",
        "\"\"\"\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.autograd\n",
        "\n",
        "\n",
        "device = torch.device('cuda')\n",
        "# 进行数据预处理和迭代器的构建\n",
        "im_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])    # 标准化\n",
        "        ])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# 手写数字识别,image and labels\n",
        "train_dataset = torchvision.datasets.MNIST(root='../mnist',\n",
        "                                           train=True,\n",
        "                                           transform = im_transforms,  # 使用了前面定义的迭代器,顺便做了数据的预处理\n",
        "                                           download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../mnist',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# 加载数据 input pipline\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# 定义网络:\n",
        "class autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(autoencoder, self).__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "                nn.Linear(28*28, 128),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(128,64),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(64,12),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(12,3)    # 输出的code是三维的code\n",
        "                )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "                nn.Linear(3,12),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(12,64),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(64,128),\n",
        "                nn.ReLU(True),\n",
        "                nn.Linear(128,28*28),\n",
        "                nn.Tanh()\n",
        "                )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encode = self.encoder(x)\n",
        "        decode = self.decoder(encode)\n",
        "        return encode, decode\n",
        "    \n",
        "net = autoencoder().cuda()\n",
        "if torch.cuda.is_available():\n",
        "  print('cuda available!!')\n",
        "  net = net.cuda()\n",
        "x = torch.autograd.Variable(torch.randn(10,28*28)).cuda()  # 随机生成一张图片,batch_size = 1\n",
        "encode, _  = net(x)\n",
        "#print(encode.shape, decode.shape)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
        "\n",
        "def to_img(x):\n",
        "    '''\n",
        "    定义一个函数,将最后输出的结果,转换回图片\n",
        "    '''\n",
        "    x = 0.5 * (x +1.)\n",
        "    x = x.clamp(0,1)\n",
        "    x = x.view(x.shape[0],1,28,28)\n",
        "    return x\n",
        "\n",
        "# 开始训练自动编码器\n",
        "for e in range(10):\n",
        "    count = 0\n",
        "    for im,_ in train_dataset:\n",
        "        im = im.view(im.shape[0],-1).cuda()\n",
        "        im = torch.autograd.Variable(im).cuda()\n",
        "        \n",
        "        # 向前传播\n",
        "        _, output = net(im)\n",
        "        loss = criterion(output,im)/im.shape[0]\n",
        "        \n",
        "        # 反向传播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        count+=1\n",
        "        if (count%5000==0):\n",
        "          print('count:{}'.format(count))\n",
        "        \n",
        "    \n",
        "    if (e+1)%2 == 0:\n",
        "        print('epoch: {}, Loss: {}'.format(e+1, loss.data))\n",
        "        pic = to_img(output.data)\n",
        "        \n",
        "        # os.mkdir('./simple_autoencoder')\n",
        "        torchvision.utils.save_image(pic,'./simple_autoencoder/image_{}.jpg'.format(e+1))            "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda available!!\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "epoch: 2, Loss: 0.19224104285240173\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "epoch: 4, Loss: 0.19224104285240173\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "epoch: 6, Loss: 0.19224104285240173\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "epoch: 8, Loss: 0.19224104285240173\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "count:5000\n",
            "count:10000\n",
            "count:15000\n",
            "count:20000\n",
            "count:25000\n",
            "count:30000\n",
            "count:35000\n",
            "count:40000\n",
            "count:45000\n",
            "count:50000\n",
            "count:55000\n",
            "count:60000\n",
            "epoch: 10, Loss: 0.19224104285240173\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}